{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import all needed libraries\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL Global varibale and path to KITTI dataset\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset paths ##\n",
    "dataset_path = '../dataset/sequences/03/image_0/'\n",
    "dataset_pose_path = \"../dataset/poses/03.txt\"\n",
    "## Camera intrinsic paramters ##\n",
    "k = np.array([[7.188560000000e+02, 0.000000000000e+00, 6.071928000000e+02],\n",
    "     [0.000000000000e+00, 7.188560000000e+02, 1.852157000000e+02],\n",
    "     [0.000000000000e+00, 0.000000000000e+00, 1.000000000000e+00]], dtype=np.float32)\n",
    "## Min feature number to track ## \n",
    "kMinNumFeature = 3000\n",
    "## Create empty image to draw trajectory ## \n",
    "traj = np.zeros((600, 600, 3), dtype=np.uint8)\n",
    "x_loc = []\n",
    "z_loc = []\n",
    "cur_R = None\n",
    "cur_t = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset from path folder to list of image paths\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_dataset(dataset_path):\n",
    "    seq00_list = [dataset_path+f for f in listdir(dataset_path) if isfile(join(dataset_path, f))]\n",
    "    seq00_list.sort()\n",
    "    return seq00_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Ground truth pose of the vehicle\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_gt_trajectory(dataset_pose_path):\n",
    "    file_09 = open(dataset_pose_path,\"r\") \n",
    "    lines = file_09.readlines()\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for i in lines:\n",
    "        x.append(i.split(' ')[3])\n",
    "        y.append(i.split(' ')[7])\n",
    "        z.append(i.split(' ')[11])\n",
    "    file_09.close()\n",
    "    gt_trajectory =  np.stack((x, y, z)).astype(np.float32)\n",
    "    return gt_trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Tracking function, take two Consecutive frames and fetures to track**\n",
    "--                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#    image_ref: frame at (t-1)                                       #\n",
    "#    image_cur: frame at (t)                                         #\n",
    "#    px_ref: feature at the frame (t-1)                              # \n",
    "######################################################################\n",
    "\n",
    "def featureTracking(image_ref, image_cur, px_ref):\n",
    "    lk_params = dict(winSize  = (21, 21), \n",
    "                    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "    \n",
    "    kp2, st, err = cv2.calcOpticalFlowPyrLK(image_ref, image_cur, px_ref, None, **lk_params)  \n",
    "\n",
    "    st = st.reshape(st.shape[0])\n",
    "    kp1 = px_ref[st == 1]\n",
    "    kp2 = kp2[st == 1]\n",
    "\n",
    "    return kp1, kp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a monocular visual odometry, The algorithme can not scale the movement (unit of the distance) so we need to find the right scale from the ground truth trajectory\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#    gt_trajectory: Ground truth trajectory matrix                   #\n",
    "#    frame_id: frame number                                          #\n",
    "######################################################################\n",
    "def getAbsoluteScale(gt_trajectory, frame_id):  \n",
    "    x_prev = float(gt_trajectory[0, frame_id-1])\n",
    "    y_prev = float(gt_trajectory[1, frame_id-1])\n",
    "    z_prev = float(gt_trajectory[2, frame_id-1])\n",
    "    x = float(gt_trajectory[0, frame_id])\n",
    "    y = float(gt_trajectory[1, frame_id])\n",
    "    z = float(gt_trajectory[2, frame_id])\n",
    "    return np.sqrt((x - x_prev)*(x - x_prev) + (y - y_prev)*(y - y_prev) + (z - z_prev)*(z - z_prev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_first_frames(first_frame, second_frame, k):\n",
    "    det = cv2.FastFeatureDetector_create(threshold=20, nonmaxSuppression=True)\n",
    "    kp1 = det.detect(first_frame)\n",
    "    kp1 = np.array([x.pt for x in kp1], dtype=np.float32)\n",
    "\n",
    "    kp1, kp2 = featureTracking(first_frame, second_frame, kp1)\n",
    "    E, mask = cv2.findEssentialMat(kp2, kp1, k, method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "    _, R, t, mask = cv2.recoverPose(E, kp2, kp1, k)\n",
    "    kp1 = kp2\n",
    "    return kp1, R, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call init function to start the main loop\n",
    "--\n",
    "Read dataset image.\n",
    "Read dataset ground truth pose.\n",
    "process first two image to start the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq00_list = Read_dataset(dataset_path)\n",
    "gt_trajectory = Read_gt_trajectory(dataset_pose_path)\n",
    "first_frame = cv2.imread(seq00_list[0], 0)\n",
    "second_frame = cv2.imread(seq00_list[1], 0)\n",
    "kp1, cur_R, cur_t = process_first_frames(first_frame, second_frame, k)\n",
    "last_frame = second_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main loop\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main loop ## \n",
    "for i in range(len(seq00_list)):\n",
    "    ## read the new frame from the image paths list ## \n",
    "    new_frame = cv2.imread(seq00_list[i], 0)\n",
    "    ## track the feature movement from prev frame to current frame ## \n",
    "    kp1, kp2 = featureTracking(last_frame, new_frame, kp1)\n",
    "    ## find the rotation and translation matrix ##\n",
    "    E, mask = cv2.findEssentialMat(kp2, kp1, k, method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "    _, R, t, mask = cv2.recoverPose(E, kp2, kp1, k)\n",
    "    ## find the change of the feature location ## \n",
    "    change = np.mean(np.abs(kp2 - kp1))\n",
    "    ## find the scale of the movemnt from the ground truth trajectory ## \n",
    "    absolute_scale = getAbsoluteScale(gt_trajectory, i)\n",
    "    if absolute_scale > 2:\n",
    "        absolute_scale = 1\n",
    "    ## check if the vehicle not moving by check the change value ## \n",
    "    if change > 5:\n",
    "        ## accumulate the translation and rotation to find the X, Y, Z locations ## \n",
    "        cur_t = cur_t + absolute_scale * cur_R.dot(t)\n",
    "        cur_R = R.dot(cur_R)\n",
    "    ## if the number of detect features below threshold value recaulc the feature ## \n",
    "    if(kp1.shape[0] < kMinNumFeature):\n",
    "        det = cv2.FastFeatureDetector_create(threshold=20, nonmaxSuppression=True)\n",
    "        kp2 = det.detect(new_frame)\n",
    "        kp2 = np.array([x.pt for x in kp2], dtype=np.float32)\n",
    "    ## Get ready for the next loop ##\n",
    "    kp1 = kp2\n",
    "    last_frame = new_frame\n",
    "    ## start after the first two frames ##\n",
    "    if i > 2 :\n",
    "        x, y, z = cur_t[0], cur_t[1], cur_t[2]\n",
    "    else:\n",
    "        x, y, z = 0.0, 0.0, 0.0\n",
    "    ## save x, z loc ##\n",
    "    x_loc.append(x)\n",
    "    z_loc.append(z)\n",
    "    ## Draw trajectory ##\n",
    "    draw_x, draw_y = int(x)+290, int(z)+90\n",
    "    true_x, true_y = int(gt_trajectory[0, i])+290, int(gt_trajectory[2, i])+90\n",
    "    cv2.circle(traj, (draw_x,draw_y), 1, (0,0,255), 1)\n",
    "    cv2.circle(traj, (true_x,true_y), 1, (0,255,0), 2)\n",
    "    cv2.rectangle(traj, (10, 20), (600, 60), (0,0,0), -1)\n",
    "    text = \"Coordinates: x=%2fm y=%2fm z=%2fm\"%(x,y,z)\n",
    "    cv2.putText(traj, text, (20,40), cv2.FONT_HERSHEY_PLAIN, 1, (255,255,255), 1, 8)\n",
    "    cv2.imshow('Road facing camera', new_frame)\n",
    "    cv2.imshow('Trajectory', traj)\n",
    "    # Close the frame\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Release and Destroy\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('map.png', traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find mean Error ##\n",
    "Error = np.mean((gt_trajectory[0] - x_loc)**2 + (gt_trajectory[2] - z_loc)**2)\n",
    "print(\"Mean Error: \"+ str(Error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Result X Z location\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Result ##\n",
    "plt.figure(figsize=(8, 8), dpi=100)\n",
    "plt.title(\"X Z Trajectory\")\n",
    "plt.ylabel(\"X\")\n",
    "plt.xlabel(\"Z\")\n",
    "plt.plot(x_loc, z_loc, label=\"MVO-Trajectory\")\n",
    "plt.plot(gt_trajectory[0], gt_trajectory[2], label=\"GT-Trajectory\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
